\chapter[Forschungsfrage 1]{Wie können Container-Anwendungen den Prozess des automatisierten \enquote{Deployments} unterstützen?} \label{ff1}
Dieses Kapitel beschreibt die Entwicklung eines Verteilungsprozesses der Container-Anwendungen mit der, für die Abteilung \ac{IE2} zentralen, Software \textsc{Ara}\footnote{\enquote{Automic Automation gives you the agility, speed and reliability required for effective Digital Business Automation. From a single unified platform, Automic centrally delivers the Workload Automation, Self-Service Automation, and Big Data Automation capabilities needed to drive growth of your company and accelerate your digital transformation.} Quelle: \cite{broadcom_inc_automic_2020}}. Zuerst werden Grundlagen der Anforderungsanalyse, der \enquote{Cloud}-Technologie und der Containerisierung gelegt. Danach folgt die Dokumentation der Entwicklung des automatisierten Prozesses, sowie Definition einer Übergabe- und Konfigurationsdatei. Ziel dieses Kapitels ist es, die Forschungsfrage eins zu beleuchten und ein fundiertes Ergebnis zu erzeugen.

\section{Grundlagen: Definition der Begrifflichkeiten zur Forschungsfrage eins}
Dieses Teilkapitel soll grundlegende Begrifflichkeiten, die im weiteren Verlauf dieser Arbeit verwendet werden, definieren, um so eine einheitliche Terminologie der Begriffe zu entwickeln. Dadurch wird ein gemeinsames Verständnis erzeugt.

\subsection{Methodik der Anforderungsanalyse}\label{kap:methodikAnfAnalyse}
Die Anforderungsanalyse leitet sich aus dem thematischen Komplex des \enquote{Requirements-Engineering} ab, die verschiedene Bedeutungsvarianten besitzt -- dabei \enquote{[...] steht [es] einmal für alle konkreten Aktivitäten am Beginn einer Systementwicklung, die auf eine Präzisierung der Problemstellung abzielen. Ebenso steht es aber auch für eine ganze Teildisziplin im Grenzbereich zwischen Systems-Engineering, Informatik und Anwendungswissenschaften.}\autocite[][S.\,19]{partsch_requirements-engineering_2010} Diese Analyse soll, laut der herrschenden Meinung der Wissenschaft, am Anfang jeder Systementwicklung stehen, um so bestimmte Vorgehensweise anzuwenden. Dabei entstehen, wenn der später weiter definierte Prozess verfolgt wird, viele systematisch verbundene Dokumente, die Anforderungen enthalten. So ist jede Anforderung wieder ein Cluster von kleineren Anforderungen, die miteinander verbunden sind. Diese werden durch den IEEE-Standard 1220 definiert als \enquote{a statement that identifies a product or process operational, functional, or design characteristic or constraint, which is unambiguous, testable or measurable, and necessary for product or process acceptability (by consumers or internal quality assurance guidelines).}\autocite[][S.\,9]{IEEE1220-2005SystemsEng} Dieser Standard legt mit höchster Priorität den Fokus auf die Formulierung einer Anforderung als elementar wichtig für das Produkt bzw. für das Erreichen der Akzeptanz des Produktes. Ziel der Analyse ist es, funktionale und nicht-funktionale Anforderungen zu identifizieren und diese testbar zu dokumentieren. Funktionale Anforderungen definieren genau, was ein System später erfüllen muss, sie ergeben sich aus der Fragestellung \enquote{Was tut das System?/Was soll es aufgrund der Aufgabenstellung können?}\autocite[][S.\,27]{partsch_requirements-engineering_2010} Nicht-funktionale Anforderungen konkretisieren die Qualitätsansprüche an das System, die Forderung an das zu implementierende System als Ganzes, sowie Randbedingungen, die aus Projekt-/Prozess-/Unternehmensbedingungen resultieren können.\autocite[vgl.][S.\,27-29]{partsch_requirements-engineering_2010}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.38]{img/levels-of-requirements-engineering.pdf}
	\caption{Entwicklungsprozess der Anforderungen}
	{\footnotesize \cite[Quelle: in Anlehnung an ][S.\,28]{hull_requirements_2011}}
	\label{abb:entwAnforderung}
	%		{\scriptsize \textit{Alle Rechte, einschließlich der Vervielfältigung, Veröffentlichung, Bearbeitung und Übersetzung bleiben der SV Informatik GmbH vorbehalten.}}
\end{figure}

Das \enquote{statement of needs} ist der Startpunkt für die Entwicklung einer Anforderung die am Ende des Prozesses, der in Abbildung \vref{abb:entwAnforderung} dargestellt ist, präzise dokumentiert sein wird. Dieses ist am Anfang immer ein Ausdruck eines Anspruchs oder Wunsches an das zu entwerfende System; dabei bildet das \enquote{statement} und die \enquote{stakeholder requirements} die \enquote{problem domain}. Diese definiert grundständige Methodik, wie auch eine nicht-technische Herangehensweise, die auf die Projektbeteiligten (\enquote{stakeholder}) angepasst ist. Nachfolgend werden die Projektbeteiligen als \enquote{stakeholder} bezeichnen, dabei ist die Rolle beschrieben als \enquote{(Stakeholder) sind Personen oder Organisationen, die ein potenzielles Interesse an einem zukünftigen System haben und somit in der Regel auch Anforderungen an das System stellen.}\autocite[][S.\,8]{partsch_requirements-engineering_2010} Später definiert die \enquote{problem domain} den Zweck des Systems -- dadurch ist bei der Ermittlung der Anforderungen die Frage \enquote{Was ist der Zweck des Systems?} anstelle \enquote{Was soll das System ihrer Meinung nach tun?}. Dies soll die \enquote{stakeholder} extrinsisch motivieren über den Zweck des zu entwerfenden Systems und nicht über einen möglichen Lösungsweg (das Wie) nachzudenken. Durch diesen Ansatz folgen Antworten nach dem Muster \enquote{Ich möchte etwas tun können ...} -- wissenschaftlich bzw. literarisch betrachtet sind diese Form der Anforderungen als \enquote{capability requirement(s)}\autocite[vgl.][S.\,94]{hull_requirements_2011} bekannt. Sie stellen die wichtigsten Erkenntnisse in der \enquote{problem domain} dar. Nun wird im weiteren Verlauf ein Modell konstruiert, das den Projektbeteiligten, den \enquote{stakeholder}, präsentiert wird. Dies unterliegt der Einschränkung, dass es jede/jedem Projektbeteiligte/n versteht. Denn sie validieren das konstruiert Modell in jedem weiteren Schritt, der in Abbildung \vref{abb:entwAnforderung}, ersichtlich ist. Die Anforderungen an das Modell sind quantitativ gering: es muss nicht-technisch sein und es muss geeignet sein die Anforderungen an das System abzubilden. Eine solche Darstellung ist dann geeignet, wenn sie den gewünschten Zweck an das System abbildet, das heißt, dass sie keine technischen Details zeigt, sondern einen Überblick bietet. Ein \enquote{use scenario}\autocite[vgl.][S.\,94]{hull_requirements_2011} wird meist verwendet, da es sich eignet menschliche Aktionen bzw. Ziele darzustellen. Abschließend müssen die \enquote{stakeholder}-Anforderungen folgende Kriterien erfüllen: 

\begin{itemize}
	\item kurz und prägnant formulierte Beschreibung, jedoch einfach zu verstehen und
	\item gleichzeitig sollten sie nicht-technisch, aber realistisch formuliert sein.
\end{itemize}
 
 Die \enquote{solutions domain}, die auf Abbildung \vref{abb:entwAnforderung} zu sehen ist, ist die Nachfolgerin von der \enquote{problem domain}. Der Hauptunterschied zwischen den beiden Bereichen ist, dass die \enquote{solution domain} idealtypisch qualitativ hochwertig beschriebene Anforderungen als \enquote{Input} bekommt. Dazu konträr erhält die \enquote{problem domain} vage formulierte Wunschliste oder einem nicht klar definierten Ziel als initialen \enquote{Input}. Ausgehend von der Aussage von E. Hull, \enquote{in an ideal world, all the requirements would be clearly articulated, individual test able requirements}\autocite[][S.\,115]{hull_requirements_2011}, ist zu deduzieren, dass viele Ebenen zu erforschen gibt, um dieser Aufforderung zu entsprechen. So muss iterativ in jeder Ebene eine neue Analyse des \enquote{Inputs} erfolgen, um einen Ausgangspunkt für das weitere Vorgehen zu initialisieren. Die Komplexität diese Ebenen ist anhängig von dem Grad der Innovation sowie vom Kontext des zu entwickelnden Systems. Jede Entscheidung während des Prozesses kann mögliche Entscheidungspfade in einer anderen Ebene verhindern. Ziel des Prozesses ist es, ein Anforderungsdokument/-katalog zu entwerfen, das laut der gesichteten Literatur in verschiedenen Repräsentationen vorliegen kann. Dennoch sollten primäre Bestandteile, wie die Rahmenbedingungen, die Projektbeteiligten, die Projektaspekte und die funktionale/nicht-funktionale Anforderungen, enthalten sein. Ein Beispiel dieses Katalogs ist im Anhang \vref{appendixAnforderung} zur Ansicht enthalten. Außerdem gibt es im Bereich der \enquote{Cloud} besondere architektonische Anforderungen. Diese sind im Anhang als Abbildung \vref{abb:cloudreq} einzusehen.
 
\subsection{\ac{Cloud-C}}
\ac{Cloud-C}, definiert als: \enquote{Paradigma, einen netzwerkbasierten Zugang auf ein skalierbares und  elastisches Reservoir gemeinsam nutzbarer physikalischer oder virtueller Ressourcen nach dem Selbstbedienungsprinzip und bedarfsgerechter Administration zu ermöglichen}\autocite[][S.\,7]{dindeutsches_institut_fur_normung_informationstechnik_2020-2}, ist ein neuartiger und disruptiver Ansatz in der Informationstechnologie, der seit mehreren Jahren Führungskräfte und IT-Abteilungen beschäftigt. Dieser Ansatz verspricht die Lösung für sämtliche Herausforderungen der Kapazitäts- und Leistungsengpässe moderner IT-Infrastruktur zu sein.\autocite[vgl.][S.\,4]{reinheimer_cloud_2018} Auch diskutiert die Bevölkerung stark und meist auch sehr kontrovers über dieses Thema -- Themen wie Datenschutz und Privatsphäre; Risiko eines Datendiebstahls und die rechtlichen Fragen sind auch nach 20 Jahren Diskussion immer noch allgegenwärtig. Ein Grund dafür ist die hohe Dynamik dieser Technologie, sowie die ständige Weiterentwicklung, die von großen Unternehmen, wie \textsc{Microsoft}, \textsc{Google}, \textsc{Amazon} und \textsc{IBM}, vorangetrieben werden. Momentan haben \textsc{Microsoft} und \textsc{Amazon} die meisten Marktanteile am Umsatz im Bereich des \ac{Cloud-C}.\footnote{siehe dazu Abbildung \vref{abb:marktanteileCC19}} Des Weiteren prognostiziert \cite{gartner_cloud_2019} einen exponentiell wachsenden weltweiten Umsatz bis 2022 auf ungefähr 354,6 Milliarden US-Dollar. Damit würde dieser in den nächsten zwei Jahren um circa 100 Milliarden US-Dollar steigen. Für eine ausführliche Umsatzprognose ist auf die Abbildung \vref{abb:umsatzprognoseCC} zu verweisen. Diese verdeutlicht auch, dass in den folgenden Jahren nach 2022 weiterhin mit einer exponentiellen Umsatzsteigerung zu rechnen ist, wenn das mathematische Modell der exponentiellen Regression weiterhin Bestand hat. 
\par
Historisch betrachtet leitet sich \ac{Cloud-C} an verschiedenen Konzepten anderer \enquote{Comput-ing}-Bereiche und Architekturmustern ab: So spielte zur Entwicklung des heutigen Verständnis \enquote{Utility Computing}, \enquote{Service Orientation} und \enquote{Grid Computing} eine große Rolle.\autocite[vgl.][S.\,3-5]{hill_guide_2013} John McCarthy hat in den 1960er-Jahren das erste Konzept im Bereich des \enquote{Utility Computing} entwickelt.\autocite[vgl.][]{mccarthy_reminiscences_1983} Später wurde es durch Douglas Parkhill verfeinert und durch die folgenden Schlüsselkomponenten beschrieben: \enquote{Parkhill examined the nature of utilities such as water, natural gas and electricity in the way they are provided to create an understanding of the characteristics that computing would require if it was truly a utility. When we consider electricity supply, for example, in the developed world, we tend to take it for granted that the actual electrical power will be available in our dwellings. To access it, we plug our devices into wall sockets and draw the power we need. Every so often we are billed by the electricity supply company, and we pay for what we have used}.\autocite[vgl.][]{parkhill_challenge_1966} Dieses Konzept leitete er auch auf eine technologische Ressource im Bereich des Computers ab.\autocite[vgl.][S.\,4]{hill_guide_2013} Der Gedanke der Serviceorientierung beschreibt eine klare Begrenzung einer Funktion, die zur Erfüllung eines bestimmten Ziels verwendet wird. Services werden meist durch die Konzepte der Objektorientierung und der Abstraktion in einer Organisation definiert. Aus dem Grundgedanken und den genannten Konzepten entwickelt sich die \ac{SOA}, die diese Prinzipien in ein technologiebasiertes Modell abbildet. Die Leitgedanken der \ac{SOA} spielen auch im \ac{Cloud-C} eine wichtige Rolle, denn, wie später noch näher definiert, ist der Servicegedanke ein elementarer Bestandteil der \enquote{Cloud}, der deutlich das Geschäftsmodell prägt. \enquote{Grid Computing} ist ein Konzept aus den 1990er-Jahren und fand seine Anwendung im Bereich der elektrischen Netze.\autocite[vgl.][]{weinhardt_cloud_2009} Ziel dieses Konzeptes war es, die Einfachheit und Zuverlässigkeit der Stromnetze zu gewährleisten über einen standardisierten Adapter Zugriff auf dieses zu erhalten ohne sich um die technische Realisierung kümmern zu müssen. Dabei stellten die Pioniere dieses Konzeptes folgende Eigenschaften\autocite[vgl.][]{foster_grid_1999} an das System:

\begin{itemize}
	\item Dezentrale Ressourcenkontrolle, d.\,h. ein Grid besteht aus geografisch verteilten Ressourcen, die administrativ unabhängig von Organisationen betreut werden.	
	\item Standardisierte, offene Protokolle und Schnittstellen, d.\,h. die Grid-Middleware
	ist nicht anwendungsspezifisch und kann zu verschiedenen Zwecken eingesetzt
	werden.
	\item Nichttriviale Eigenschaften des Dienstes, z. B. in Bezug auf Antwortzeitverhalten, Verfügbarkeit oder Durchsatz.
\end{itemize}
Diese Prinzipien haben eine Ähnlichkeit zu denen des \ac{Cloud-C}, jedoch sind die wirtschaftlichen Aspekte durch die Gedanken des \enquote{Grid Computing} beschrieben. Des Weiteren werden die Aspekte des \enquote{Grid Computings} im Bereich des dezentralen Managements und der verteilten Ressourcen beim \ac{Cloud-C} nicht weiterverfolgt. Vielmehr bietet die Zentralisierung die ökonomischen Vorteile, die eine zentrale Rolle des Geschäftsmodells darstellen. \par
Da es mehrere Definitionen von \ac{Cloud-C} gibt, beschränkt sich diese Arbeit auf folgende: \enquote{Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models.}\autocite[][S.\,2]{mell_nist_2011} Das \ac{NIST} beschreibt in der Publikation \cite{mell_nist_2011} folgende essenzielle Charakteristika\footnote{Jedoch werden diese Charakteristika in anderen wissenschaftlichen Ausarbeitungen um \enquote{multitenancy}, \enquote{service oriented} und \enquote{utility-based pricing} ergänzt.\autocite[vgl.][S.\,1]{institute_of_electrical_and_electronics_engineers_cloud_2011}}: 

\begin{itemize}
	\item on-demand self-service
	\item broad network access
	\item resource pooling
	\item rapid elasticity
	\item measured service
\end{itemize}
Des Weiteren beschreibt die \ac{NIST} drei Servicemodelle, wie sich Unternehmen die \enquote{Cloud} zunutze machen können: \ac{SaaS}, \ac{PaaS} und \ac{IaaS}. Dabei wird \ac{SaaS} definiert als: \enquote{The capability  provided to the consumer is to use the provider’s applications running on a cloud infrastructure. [...] The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.}\autocite[][S.\,2]{mell_nist_2011} \enquote{Cloud}-Infrastruktur ist eine Sammlung von Hard-/Software des \enquote{Cloud}-Anbieters, die die fünf essentiellen Charakteristika des \ac{Cloud-C} unterstützt bzw. erfüllt. Beispiele hierfür sind \textsc{Google Docs} und \textsc{Office 365}. \ac{PaaS} wird beschrieben durch: \enquote{The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. The consumer does
not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.}\autocite[][S.\,2]{mell_nist_2011} Bei der später in der Konzeptionierung verwendeten Software, \textsc{OpenShift}, handelt es sich um eine \ac{PaaS}-Lösung. Weitere Beispiele sind 
\textsc{Google App Engine}, \textsc{Windows Azure} und \textsc{Heroku}.\autocite[vgl.][S.\,8]{kumar_reliability_2018} \ac{IaaS} wird durch folgende Definition abgebildet: \enquote{The capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, and deployed applications; and possibly limited control of select networking components (e.g. host firewalls).}\autocite[][S.\,3]{mell_nist_2011} Hierzu zählen die Produkte \textsc{Amazon EC2}, \textsc{OpenStack} und \textsc{VMware}. Nun sind die Bereitstellungsmodelle der \enquote{Cloud} noch von Bedeutung -- die \ac{NIST} sowie weitere, schon für diesen Abschnitt verwendete, Literatur definiert vier Modelle: \enquote{private, community, public and hybrid cloud} Die \enquote{private cloud} ist in exklusiver Nutzung eines Unternehmens, dass mehrere interne Konsumenten bedient. Es kann entscheiden, ob alle Management-/Betriebsoperationen intern oder extern von einem Anbieter durchgeführt werden. Die \enquote{Cloud} kann intern oder extern gehostet sein. Die \enquote{community cloud} ist eine \enquote{private cloud}, jedoch unterscheiden sich die beiden durch die Benutzergruppen. Bei der \enquote{community}-Variante ist es nicht auf die Organisation sondern auf Gruppen mit gleichen Angelegenheiten beschränkt. Die \enquote{public cloud} ist offen für die Öffentlichkeit natürlich beschränkt durch die Regel des \enquote{Cloud}-Anbieter. Die hybride Variante wird folgendermaßen beschrieben: \enquote{The cloud infrastructure is a composition of two or more distinct cloud infrastructures (private, community, or public) that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds).}\autocite[][S.\,3]{mell_nist_2011}


\subsection{Container, Containerisierung und Orchestrierung}\label{kap:container}
\enquote{Historically, virtualization technologies have developed out of the need for scheduling processes as manageable container units. The processes and resources in question are the file system, memory, network, and system information.}\autocite[][S.\,25]{pahl_containerization_2015} Aus dieser Notwendigkeit heraus entstanden verschiedene Lösungsansätze: die Virtualisierung in einer virtuellen Maschine (\ac{VM}) und etwas später die Container-Lösungen. Virtuelle Maschinen konnten einige Herausforderungen, wie \enquote{scheduling, packaging and resource access}, durch ihre technologischen Ansätze lösen. Dabei wurde der architektonische Ansatz des sogenannten \enquote{Gast Systems} entwickelt, d.\,h. die virtuelle Maschine ist ein vollwertiges \ac{OS} mit kompletten Dateisystem und eigenem Prozess auf dem \enquote{Host System}\footnote{bietet Services für die Gastsysteme an}. Im Vergleich dazu können Container die gleichen Anforderung abbilden, jedoch unterscheidet sich die Architektur dieser (vgl. Abbildung \vref{abb:virutalizationArch}). Ein Container enthält alle notwendigen, für die App relevanten, Bibliotheken beziehungsweise Abhängigkeiten und kann so, ohne ein komplettes \ac{OS}, lauffähige Applikationen beinhalten. Diese Abstraktion ist im \enquote{Cloud}-Umfeld (bspw. in einer \ac{PaaS}-Ausprägung) nützlich, da die Container leichtgewichtiger sind und weniger Speicherauslastung (persistenter Speicher) dadurch benötigen. Auch später für die Orchestrierung der Container in einem Cluster-Umfeld ist dies von Nutzen. 

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.44]{img/virtualization architecture.pdf}
	\caption{Architektur der Virtualisierungsmodelle: VM vs. Container}
	{\footnotesize Quelle: in Anlehnung an \cite{pahl_containerization_2015}}
	\label{abb:virutalizationArch}
	%		{\scriptsize \textit{Alle Rechte, einschließlich der Vervielfältigung, Veröffentlichung, Bearbeitung und Übersetzung bleiben der SV Informatik GmbH vorbehalten.}}
\end{figure}

Die gesichtete Literatur (\cite{pahl_containerization_2015}, \cite{bernstein_containers_2014}, \cite{kharb_automated_2016}; \cite{combe_docker_2016} und weitere siehe Literaturverzeichnis) definieren Container immer anhand ihrer charakteristischen Merkmale und im Vergleich zur \ac{VM}. \cite{google_ireland_limited_container_2020} folgt auch diesem Muster, dennoch eher auf Makroebene: \enquote{Container bieten einen logischen Mechanismus der Paketerstellung, der darauf beruht, dass Anwendungen von ihrer Ausführungsumgebung abstrahiert werden. Mit dieser Entkopplung können containerbasierte Anwendungen einfach und konsistent bereitgestellt werden, unabhängig davon, ob es sich bei der Zielumgebung um ein privates Rechenzentrum, die öffentliche \enquote{Cloud} oder auch um den persönlichen Laptop eines Entwicklers handelt.}\autocite[][]{google_ireland_limited_container_2020} Ziel der Containerisierung ist es, Entwicklerinnen die Möglichkeit zu bieten, sich nur auf die Anwendungslogik und -abhängigkeiten zu konzentrieren. Gleichzeitig können andere IT-Teams, wie \ac{IE2}, sich um die Bereitstellung und Verwaltung dieser Container kümmern. Diese Teams können den Container als geschlossene Verpackung sehen, bei der sie keine Kenntnis über das Innenleben (die Anwendungsdetails) für ihre Arbeit benötigen.\autocite[vgl.][]{google_ireland_limited_container_2020} Dies ist ein Bestandteil der Grundlagen für schnellere und qualitativ hochwertigere Deployments.\autocite[vgl.][S.\,1]{kharb_automated_2016} \par
Initial entwickelte \cite{canonical_ltd_linux_2020} die \ac{LXC}; \textsc{Docker Inc.} ist ein \enquote{open source}-Projekt, dass sich die \ac{LXC}-Technologie zunutze macht und eine Container-\enquote{engine} gebaut hat, um diese Technologie benutzerfreundlicher zu gestalten: \enquote{Basically, \textsc{Docker} extends LXC with a kernel- and application-level API that together run processes in isolation: CPU, memory, I/O, network, and so on. \textsc{Docker} also uses namespaces to completely isolate an application’s view of the underlying operating environment, including process trees, network, user IDs, and file systems.}\autocite[][S.\,82]{bernstein_containers_2014} \textsc{Docker}-Container nutzen eine \enquote{Image}-Struktur. So lassen sich durch Kombination verschiedener \enquote{Images} Applikationen abbilden, die durch Programmierlogik ergänzt werden (vgl. Abbildung \vref{abb:containerArch}). In der Industrie ist \textsc{Docker} als de-facto Standard\autocite[vgl.][S.\,30]{pahl_containerization_2015} angesehen\autocite[vgl.][S.\,1]{kharb_automated_2016}. Außerdem bietet es viele Vorteile, wie die Lichtgewichtigkeit, \enquote{open source}, Sicherheit, Kollaboration zwischen verschiedenen IT-Teams, die Applikation kann überall (wo \textsc{Docker} installiert ist) ausgeführt werden und \textsc{Docker} passt sich an die Unternehmensanforderungen ständig neu an.\autocite[vgl.][S.\,1]{kharb_automated_2016} Durch diese Vorteile entstehen unmittelbare Konsequenzen, die Auswirkungen auf das Arbeiten haben, so wird das Einlernen eines neuen Mitarbeitenden beschleunigt, die Kreativität der Entwicklerinnen verstärkt, die Entwicklungsumgebung vereinheitlicht\footnote{Dies wirkt sich direkt auf die Code-/Produktqualität aus}, die Zusammenarbeit zwischen verschiedenen Teams wird vereinfacht und eine schnelle \enquote{\ac{TTM}}\footnote{\enquote{TTM is the strategy of focusing on reducing the time to introduce new products to market.} (\cite{pawar_time_1994})} wird erreicht.\autocite[vgl.][S.\,2]{kharb_automated_2016} 
\par 
Um die Stärken und Vorteile der \textsc{Docker}-Container, brauchen diese eine Netzwerkanbindung. Nur mit dieser können Container in der Produktion eingesetzt und eine Orchestrierung möglich gemacht werden. Dieser Begriff ist aus der Musik abgeleitet: flexibles Kombinieren mehrerer Services oder Dienste zu einer sinnvollen Konzeption (Komposition), die einen Geschäftsprozess beschreibt. Für die Orchestrierung von Container-Anwendungen wird eine weitere Technologie benötigt, die von \cite{google_llc_production-grade_2020} entwickelt und als \enquote{open source} veröffentlicht wurde: \ac{K8s}\footnote{\enquote{is an open-source system for automating deployment, scaling, and management of containerized applications.} (\cite{google_llc_production-grade_2020})}. Die Semantik des Wortes \textsc{Kubernetes} bedeutet auf Griechisch \enquote{Loste/Steuermann}. Diese Metapher beschreibt die Hauptaufgaben von \ac{K8s} zu treffend; es \enquote{verdeckt die Hardwareinfrastruktur und stellt ihr gesamtes Rechenzentrum als eine einzige, enorme Rechenressource dar. Dadurch können Sie ihre Softwarekomponenten	bereitstellen und ausführen, ohne sich darum zu kümmern, welche Server konkret unterhalb dieser Schicht laufen. Bei der Bereitstellung von Anwendungen mit mehreren Komponenten wählt \textsc{Kubernetes} für jede dieser Komponenten einen Server aus, stellt sie bereit und ermöglicht es ihr, die anderen Komponenten zu finden und mit ihnen zu kommunizieren.}\autocite[][S.\,4]{luksa_kubernetes_2018} Der Nutzen von \ac{K8s} wird bei einer großen \enquote{Cloud}-Anbieterin, wie \ac{AWS} u. a., maximiert, da es den Entwicklerinnen ermöglicht die Ausführung und Bereitstellung von Anwendungen entkoppelt von den Systemadministratorinnen zu betreiben.\autocite[vgl.][S.\,4]{luksa_kubernetes_2018} Eine grundlegende Übersicht einer \textsc{Kubernetes}-Architektur ist im Anhang \vref{abb:k8sArch} zu finden.
\par
\ac{K8s} führt einige Begrifflichkeiten ein, die nachfolgend einer Definition\autocite[][S.\,10-14]{caban_architecting_2019} (siehe Tabelle \ref{tab:definitionenK8s}) benötigen. Diese werden im weiteren Verlauf dieser Arbeit benötigt, jedoch konzentriert auf die Forschungsfrage eins. Eine detailreiche Übersicht der Architektur der oben beschrieben Konzepte ist im Anhang \vref{abb:k8sArchInteraktion} zusehen. Diese beschreibt das Zusammenwirkung der einzelnen Komponenten.
\par

\begin{longtable}[c]{@{}lp{12.0cm}@{}}
	\toprule[1.5pt]
	\textbf{Begriff} & \textbf{Definition} \\* \midrule
	\endfirsthead
	%
	\multicolumn{2}{c}%
	{{\bfseries Tabelle \thetable\ der vorherigen Seite fortgeführt.}} \\
	\toprule
	\textbf{Begriff} & \textbf{Definition} \\* \midrule
	\endhead
	%
	\bottomrule
	\endfoot
	%
	\endlastfoot
	%
	\enquote{Pod}              & \enquote{A Pod is a group of one or more tightly coupled Containers sharing a set of Linux namespaces and cgroups.} Innerhalb des \enquote{Pod} wird der Netzwerk-/\enquote{Mount}-Namensraum geteilt, dies ermöglicht die Kommunikationen innerhalb eines \enquote{Pod}. Mehrere dieser kommunizieren über \textit{localhost} \\
	\enquote{Services}         & \enquote{A Service is a Kubernetes object that maps one or more incoming ports to targetPorts at a selected set of target of Pods. These represent a microservice or an application running on the cluster.} \\
	\enquote{Worker nodes}     & \enquote{The worker nodes (formerly known as minions) host elements like the kubelet, kube-proxy, and the container runtime.} Darin sind die \enquote{Pods} enthalten, welche die Container-Anwendungen beinhalten. \\
	\enquote{Master nodes}     & \enquote{The master nodes are the nodes hosting core elements of the control plane like (not an exhaustive list) the kubeapi-server, kube-scheduler, kube-controller-manager, and in many	instances the etcd database.} Diese übernimmt die Management-Aufgaben im Cluster. \\* \bottomrule
	
		
	\caption{Definition der \enquote{\ac{K8s}}-Begrifflichkeiten}\label{tab:definitionenK8s}\\
\end{longtable}


\section{Anforderungsanalyse des zu implementierenden Prozesses}
% Anforderungskatalog \vref{tab:anforderungslisteFF1}
% Formulierungshilfen für Anforderungen \autocite[][]{rupp_formulierungsregel_2020}
Das \enquote{statement of needs} ist, wie in Kapitel \vref{kap:methodikAnfAnalyse} beschrieben, ein Wunsch beziehungsweise Anspruch an das zu entwickelnde System (hier: ein Prozess): Es sollen Container-Anwendungen automatisiert auf die \textsc{OpenShift}-Umgebung verteilt werden. Dies soll von der dafür zuständigen Abteilung im Unternehmen übernommen werden, d.\,h. die Verantwortung dieses Prozesses wird übergeben. Ziel ist es, Aufgaben und Verantwortlichkeiten so zu verteilen, dass sie dem Aufbau- sowie Ablauforganisation entsprechen. Die Entwicklungsabteilungen/-teams möchten weiterhin nicht mehr für die Verteilung der Container-Anwendungen verantwortlich sein. Des Weiteren sprechen rechtliche Aspekte gegen dies, dass die Entwicklung auf Dauer Anwendungen in die \ac{PROD} verteilt. Bei näherer Betrachtung der oben genannten Gründe ist folgendes festzustellen: es sprechen rechtliche Voraussetzung und unternehmens-organisatorische Aspekte dafür, hier ein weiteres Vorgehen anzustreben. Alleinig durch die rechtlichen Aspekte muss eine Veränderung des IST-Zustands angestrengt werden, damit ist das Vorgehen begründet und die Ermittlung der Projektbeteiligten (\enquote{stakeholder}) kann durchgeführt werden.
\par
Die Projektbeteiligten sind im engeren Sinn die Fachbereiche (also Kunden der Anwendung), die Entwicklungsteams und die \enquote{Deployment}-Abteilung. So hat der Fachbereich Interesse an einem funktionsfähigen System, die Entwicklungsteams an einem häufigen (annäherungsweise kontinuierlichem) \enquote{Deployment} und die \enquote{Deployment}-Abteilung an einem hoch automatisiertem und revisionskonformen Prozess. Dies sind nur einige Aspekte, die bei weitem nicht alle Gründe des Interesses abdecken. Es werden hier nur die \enquote{stakeholder} im engeren Sinn weiter betrachtet, da diese Arbeit sich mit der Modellierung eines automatisierten Prozesses im Bereich der Entwicklung, der wirtschaftlichen Betrachtung und der rechtlichen Sicherung dieses beschäftigt. Der Fokus liegt auf der Modellierung des Prozesses und mit diesem deckt es die engeren Projektbeteiligten ab. 
\par
Nachfolgend wird der automatisierte \enquote{Deployment}-Prozess zur Verteilung von Containern als \textit{System} bezeichnet. Dies erfolgt auf der Grundlage der Formulierungshilfe für Anforderungen nach \cite{rupp_formulierungsregel_2020}. Es werden ausschließlich die funktionalen Anforderungen \autocite[vgl.][]{international_organization_for_standardization_isoiec_2011,} betrachtet, da die erfassten alle produkt-spezifisch sind -- nicht-funktionale Anforderung sind im Gegensatz dazu produkt-unspezifisch. Zur besseren Übersichtlichkeit sind die Anforderungen mit $A_{1}, A_{2}, ..., A_{n}, n \in \mathbb{N}$ nummeriert und ein Anforderungskatalog ist im Anhang \vref{tab:anforderungslisteFF1} zu finden. Die folgenden Anforderungen $A_{1}, A_{2}, ..., A_{8}$ stammen von dem Projektbeteiligten (\enquote{stakeholder}) \enquote{Entwicklungsteam/-abteilung}. Diese wurden während einer Befragung dieses Teams am 11.März 2020 im Rahmen einer Arbeitstagung \enquote{Container-Verteilung} erhoben. Die Anforderungen $A_{9}$ und $A_{10}$ beschreiben wichtige Bedingungen der Abteilung \ac{IE2}. 
\par 
$\mathbf{A_{1}}$\textbf{: Das System muss die Möglichkeit bieten, über eine korrekte Konfigurationsdatei, alle Komponenten der Anwendung zu verteilen.}
\par
Damit gewährleistet das System beziehungsweise der Prozess die Verteilung aller Komponenten ins \textsc{OpenShift}-Cluster. Dieses benötigt die Konfigurationsdatei, um die Anwendung zu betreiben. Die Verteilung in \textsc{OpenShift} funktioniert über diese Datei, damit werden nicht die fertigen Container direkt verteilt sondern es wird nur beschrieben welche Container wohin müssen. Danach übernimmt \textsc{OpenShift} die Beschaffung der Container.
\par
$\mathbf{A_{2}}$\textbf{: Das System soll die Möglichkeit bieten über eine standardisierte Übergabedatei alle Umgebungsvariablen des Containers zu definieren.}
\par
Diese Anforderung soll die Fehler in der Konfigurationsdatei minimieren, denn diese muss korrekt formatiert sein, sonst kann sie nicht richtig verarbeitet werden. Dabei spielen Einrückungen und Leerzeichen bei der Formatierung eine wichtige Rolle. Gleichzeitig birgt dieser Umstand großes Fehlerpotential. Mit der standardisierten Übergabedatei werden die Fehler mittels automatischem Einlesen und Generierung der Konfigurationsdatei -- zumindest die Formatierungsfehler -- verhindert. Dies hat keinen Einfluss auf fachliche Fehler, z.\,B. die Angabe einer falschen Umgebungsvariablen oder eine falsche Serveradresse der Versionskontrolle.
\par
$\mathbf{A_{3}}$\textbf{: Das System muss die Möglichkeit bieten, über eine Validierung, konsistente Komponenten zu verteilen.}
\par
Dies beschreibt eine Kontrollinstanz, die Fehler erkennen soll und dann die Verteilung abbrechen oder eine Benutzeraktion fordern soll. Die Fehlerbearbeitung muss nicht komplett automatisiert sein, da sie meist Einzelfälle behandelt und diese nicht nach dem selben Muster zu lösen sind. Die Verteilung wird nach Behebung der/des Fehler(s) fortgesetzt.
\par
$\mathbf{A_{4}}$\textbf{: Das System muss die Möglichkeit bieten unabhängig von dem Inhalt des Containers diesen zu verteilen.}
\par
$A_{4}$ beschreibt die Anforderung den Vorteil von Container-Anwendungen auszunutzen: Dieser ist die Möglichkeit beim Verteilen des Container den Inhalt ignorieren zu können, da der Container eine Abstraktionsebene darstellt.\footnote{vgl. dazu Kapitel \vref{kap:container}, dass die Funktionsweise und Vorteile genauer erläutert.} Die Entwicklungsabteilung möchte diese Vorteile nutzen, \enquote{da sonst die Umstellung auf Container wenig Sinn ergeben würde}, so ihre Aussage. Dies ist keine wissenschaftlich begründete Aussage und ist deswegen als direktes Zitat markiert.
\par
$\mathbf{A_{5}}$\textbf{: Das System muss fähig sein mit \textsc{OpenShift} über das \ac{API} zu kommunizieren.}
\par
Diese Anforderung ist ein Funktionswunsch, der es ermöglicht, mittels \ac{CLI}-Kommandos mit der Anwendung \textsc{OpenShift} zu kommunizieren. Dies hat den Vorteil die internen Möglichkeiten von \textsc{OpenShift} vollständig ausnutzen zu können, z.\,B. die interne Validierung von Konfigurationsdateien.
\par
$\mathbf{A_{6}}$\textbf{: Das System soll fähig sein das \textsc{OpenShift}-Cluster zu jedem Zeitpunkt mit einem konsistenten Zustand zu verlassen.}
\par
Mit dieser Forderung soll gewährleistet werden, dass das System die \textsc{OpenShift}-Umgebung nicht unbrauchbar macht und es so zur Produktionsverhinderung kommt. Dass würde bedeuten die Kunden haben kein lauffähiges System mehr und es würde zu Umsatzausfällen, Vertrauensverlust bei den Versicherungsnehmern u.\,a. kommen. 
\par
$\mathbf{A_{7}}$\textbf{: Das System wird die Möglichkeit bieten die Verteilung von Komponenten zu unterbrechen.}
\par
$A_{7}$ beschreibt die Forderung nach einer Notfallunterbrechung, die jedoch dem System und der \textsc{OpenShift}-Umgebung keinen Schaden zufügt. Dies soll, wie $A_{6}$, ein konsistentes System hinterlassen. 
\par
$\mathbf{A_{8}}$\textbf{: Das System muss die Möglichkeit bieten, über die zentrale Verteilungssoftware \textsc{Ara}, die Verteilung der Komponenten durchzuführen.}
\par
Diese Forderung widerspricht dem Anspruch nach \cite{hull_requirements_2011}, Anforderungen ohne Bezug zu einer bestimmten Anwendung beziehungsweise einer Technologie zu formulieren. Jedoch ist es eine zwingende Forderung der Abteilung \ac{IE2} diese Technologie zu verwenden. Es sollen alle Systeme/Prozesse mit dieser umgesetzt werden.
\par
$\mathbf{A_{9}}$\textbf{: Das System muss die Möglichkeit bieten automatisiert alle notwendigen Komponenten über die Konfigurationsdatei zu erkennen und zu verteilen.}
\par
Dies ist eine Anforderung an die Vollständigkeit der Konfigurationsdatei, die die benötigten Komponenten beschreibt. Wichtig dabei ist es, dass die Konfigurationsdatei nicht nur vollständig ist, sondern auch semantisch korrekt ist. Ein zentrales Akzeptanzkriterium ist, dass das System automatisiert funktioniert und bei Normalbetrieb keine menschliche Aufsicht benötigt.
\par
$\mathbf{A_{10}}$\textbf{: Das System muss den gesetzlichen sowie sicherheitstechnischen Vorgaben entsprechen.}
\par
$A_{10}$ beschreibt eine nicht-funktionale Anforderungen, die zwingend erforderlich ist und deswegen an dieser Stelle erwähnt wird. Im Bereich der Finanzdienstleistungen, welche das Versicherungswesen inkludieren, sind strenge Sicherheitsvorschriften und gesetzliche Rahmenbedingung einzuhalten (vgl. dazu die Forschungsfrage drei im Kapitel \vref{ff3}). Diese nicht-funktionale Anforderung ist an alle Vorhaben/Projekte gerichtet und wird von dem Projektbeteiligten \enquote{Geschäftsführung} eingebracht. Diese Anforderung muss zwingend umgesetzt werden. 

\section{Konzeption eines Container-basierten, automatisierten \enquote{Deployments}}
Dieses Teilkapitel beschreibt den Aufbau einer \textsc{OpenShift}-Labor-Umgebung, um das Verhalten von \textsc{OpenShift} zu testen. Des Weiteren wird eine Prozessmodellierung des automatisierten \enquote{Deployments} anhand einer Beispielanwendung \textsc{Camunda} erläutert. Dies ist gleichzeitig die Testapplikation, die in der \ac{SVI} benutzt wird, um das automatisierte \enquote{Deployment} von Container-Anwendungen zu untersuchen. Abschließend wird eine generische Konfigurationsdatei entwickelt, um Applikationen ins \textsc{OpenShift}-Cluster zu verteilen.

\subsection{Aufbau und \enquote{Deployment} eines \textsc{OpenShift}-Labors}
Nachfolgend wird der Aufbau einer \textsc{OpenShift}-Labor-Umgebung mit \enquote{single node}-Architektur beschrieben, d.\,h. es ist nur eine \enquote{worker node} im \textsc{OpenShift}-Cluster vorhanden. Dieses wird auf einem \textsc{Ubuntu}-System in der Version 18.04 installiert. Der folgende Quelltext \vref{lst:openShift} beschreibt die Terminal-Eingaben:

\begin{lstlisting}[language=bash, caption={Installation des \textsc{OpenShift}-Clusters}, label=lst:openShift]
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt update && sudo apt -y install docker-ce
docker version
sudo usermod -aG docker $USER
wget $LINK
tar xvf openshift-origin-client-tools*.tar.gz
cd openshift-origin-client*/
sudo mv  oc kubectl  /usr/local/bin/
oc version 
cat << EOF | sudo tee /etc/docker/daemon.json 
{
"insecure-registries" : [ "172.30.0.0/16" ]
}
EOF
sudo systemctl restart docker
oc cluster up
\end{lstlisting}

Das Konzept dieses \enquote{Shell}-Skripts \vref{lst:openShift} ist es, zuerst die notwendigen Abhängigkeiten und danach die \textsc{OpenShift}-Anwendungen zu installieren. So wird in den Zeilen eins bis drei die notwendigen Voraussetzungen geschaffen, um die \textsc{Docker}-Umgebung zu installieren. Zuerst wird der \textsc{GPG}\footnote{\enquote{GnuPG is a complete and free implementation of the OpenPGP standard as defined by RFC4880 (also known as PGP). GnuPG allows you to encrypt and sign your data and communications; it features a versatile key management system, along with access modules for all kinds of public key directories.} Quelle: \cite{the_people_of_the_gnupg_project_gnu_2020}}-Schlüssel zum lokalen Schlüsselbund hinzugefügt, danach kann die Anwendung \textsc{Docker} mit dem \ac{APT}-Programm heruntergeladen und installiert werden. Danach wird getestet, ob die Installation von \textsc{Docker} erfolgreich war und der eigene Benutzer wird der Gruppe \enquote{docker} hinzugefügt. Dies wird benötigt um dem eigenen Benutzer die Steuerung der Software \textsc{Docker} zu erlauben. Die Zeilen sechs bis neun installieren \textsc{Kubernetes} und \textsc{OpenShift} (in der \enquote{Community}-Variante). Sehr wichtig sind die Anpassungen, die in den Zeilen elf bis fünfzehn vorgenommen werden: Sie fügen einen Eintrag \lstinline[language=bash]|"insecure-registries" : [ "172.30.0.0/16" ]| in die Datei \lstinline[language=bash]|/etc/docker/daemon.json| ein. Dies erlaubt es \textsc{Docker} auf unsichere Verzeichnisse zuzugreifen; dadurch kann \textsc{OpenShift} lokal Container-\enquote{Images} im Cache speichern, um diese schneller wiederzuverwenden. Schließlich wird ein Cluster in \enquote{default}-Konfiguration zur Kontrolle der Funktionsfähigkeit mit \lstinline[language=bash]|oc cluster up| erstellt. Dies ist unter \lstinline[language=HTML, breaklines=true]|http://127.0.0.1:8443/console| als Web-Konsole erreichbar.
\par
Um das Verhalten des \textsc{OpenShift}-Clusters während eines \enquote{Deployments} zu testen, wird ein Test-Projekt erstellt. Grundsätzlich sind die meisten Kommandos der \ac{CLI} nach dem Muster \lstinline[language=sh]|oc <action> <object type> <obj name or id>|\autocite[vgl.][]{red_hat_inc_cli_2020} aufgebaut. Ein Projekt ist in \textsc{OpenShift} ein privater Bereich, indem Applikationen laufen können und nur die Erstellerin administrativen Zugriff besitzt. Dieser kann nach außen veröffentlicht werden, wenn dies erforderlich ist. Nachdem das Projekt mit \lstinline[language=bash]|oc new-project <projectName> --display-name '<displayName>'|\footnote{\enquote{<Platzhalter>}, die mit Werten vor der Ausführung ersetzt werden müssen} erstellt wurde, wird dies automatisch als \enquote{default}-Projekt ausgewählt, d.\,h. darin werden nun alle folgenden Schritte ausgeführt. Des Weiteren ist die Überlegung zu treffen, ob noch weitere Benutzer für das angelegte Projekt eine Berechtigung erhalten (\lstinline[language=bash]|oc adm policy add-role-to-user <admin/edit/view> <collabUser>|). 
\par
Als Test-Applikation soll eine Webseite auf Basis von \textsc{Django}\footnote{\enquote{Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design.} Quelle: \cite[][]{django_software_foundation_web_2020}} in Cluster verteilt werden. Es wird ein vorgefertigtes \enquote{Image} für diesen Test genutzt. Der Quellcode \vref{lst:openShiftDeployLab} zeigt die benötigten Kommandos, um eine neue Applikation zu erstellen. Des Weiteren illustriert dieser, wie die Anwendung nach außen freigegeben wird, d.\,h. sie ist außerhalb des Projektes erreichbar. Danach wird in Zeile \vref{lst:line:testConn} der Quellcode-Abbildung \vref{lst:openShiftDeployLab} die Verbindung zur Webseite mittels der Ermittlung des \textsc{HTTP}-Status-Codes überprüft\footnote{Der Quelltext dieser Funktion ist im Anhang \vref{lst:testConnection} einzusehen}.

\begin{lstlisting}[language=bash, caption={Test-\enquote{Deployment} ins \textsc{OpenShift}-Cluster}, label={lst:openShiftDeployLab}]
oc new-app openshiftkatacoda/blog-django-py --name blog
oc describe svc/blog # print config 
oc expose svn/blog
oc status | grep 'to pod port' # see all exposed services on this project

# test_connection is listed at @\vref{lst:testConnection}@
test_connection blog-lab.127.0.0.1.nip.io @\label{lst:line:testConn}@
\end{lstlisting}

Nach Abschluss des Tests wird die Applikation mit \lstinline[language=bash]|oc delete all --selector app=blog| wieder gelöscht.

\subsection{Modellierung einer \enquote{Deployment}-Konfigurationsdatei}
Um eine Verteilung der Container-Anwendung auf dem \textsc{OpenShift}-Cluster durchzuführen, benötigt das System eine Konfigurationsdatei, die als \ac{API}-Objekt an \textsc{OpenShift} übergeben wird. Dabei definiert diese den gewünschten Zustand einer bestimmten Komponente der Anwendung als \enquote{pod}\footnote{siehe Tabelle \vref{tab:definitionenK8s}}-Vorlage.\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019} Diese Datei stellt, als alleinige Quelle (\ac{SPOT}), alle notwendigen Informationen bereit, die die Anwendungen \textsc{OpenShift} benötigt, um eine funktionsfähige Datei in dem ausgewählten Projekt des Clusters bereitzustellen. Dies ist der erste Unterschied zum klassischen \enquote{Deployment} bei dem alle Quelldateien verteilt werden müssen.\autocite[vgl.][]{dearle_software_2007} Dabei ist die Konfigurationsdatei deklarativ\footnote{Programmierparadigma: im Gegensatz dazu gibt es das imperative Vorgehen, dass das \textit{Was} in welcher Reihenfolge zu tun ist beschreibt.} beschreiben, d.\,h. sie beschreibt \textit{was} \textsc{OpenShift} mit der angegeben Komponente machen soll.

Es gibt zwei verschiedene Ausprägungen der Konfigurationsdatei: \enquote{DeploymentConfig} und \enquote{Deployment}. Nachfolgend werden die Ziele, der Nutzen und ein Beispiel der Ausprägung beschrieben. Die \enquote{DeploymentConfig}-Variante ist von \textsc{Red Hat} für \textsc{OpenShift} entwickelt worden, um eine erweiterte Unterstützung für die Softwareentwicklung und den Lebenszyklus des \enquote{Deployments} zu unterstützen. Damit hat \textsc{Red Hat} ein eigenes Konzept entwickelt, wie die Verteilung von Software aussehen kann. Dieses Konzept bietet folgende Eigenschaften, die verschiedene Nutzungsmöglichkeiten ermöglichen:\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019}
\begin{enumerate}
	\item \enquote{A DeploymentConfig, which is a template for running applications.}
	\item \enquote{Triggers that drive automated deployments in response to events.}
	\item \enquote{User-customizable deployment strategies to transition from the previous version to the new version. A strategy runs inside a Pod commonly referred as the deployment process.}
	\item \enquote{A set of hooks (lifecycle hooks) for executing custom behavior in different points during the lifecycle of a deployment.}
	\item \enquote{Versioning of your application in order to support rollbacks either manually or automatically in case of deployment failure.}
	\item \enquote{Manual replication scaling and autoscaling.} 
\end{enumerate}
Allgemein definiert das \enquote{DeploymentConfig}-Objekt die Anzahl der Replikationen, beschreibt die Auslöser (\enquote{trigger}) für die automatische Erstellung von neuen \enquote{Deployments}; die Strategie, mit der die Übergange zwischen verschiedenen Versionsständen verwaltet sind, und Lebenszyklus-\enquote{Hooks}\footnote{Funktionen, die beim Eintreten eines bestimmten Events automatisch ausgelöst werden}. Wenn eine neue Verteilung von Komponenten angestoßen wird, aktiviert sich ein spezieller \enquote{pod}, um die die Verteilung zu überwachen und zu betreuen. Dieser fährt die alten Replikationen herunter, aktiviert neue und startet die \enquote{hooks}. Wichtig ist, dass er die alten Replikationen behält, um ein schnelles \enquote{rollback}, also eine Wiederherstellung des Zustands vor der aktuellen Verteilung, zu ermöglichen. Der Verteilungs-\enquote{pod} bleibt für unbestimmte Zeit im Cluster, damit die Logdatei nicht gelöscht wird. 

\lstinputlisting[language=yaml, caption={Beispiel einer \enquote{DeploymentConfig}-Datei}, label=lst:demoDeploymentConfig]{resources/listings/deploymentConfigDemo.yaml}

Dieser Quellcode \vref{lst:demoDeploymentConfig}\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019} zeigt eine Ausprägung der \enquote{DeploymentConfig}. Die Zeilen 10\,ff. beschreibt typische \enquote{trigger}, die bei einem gewissen Ereignis ausgelöst werden. Die Bezeichner beschreiben die Funktionsweise ausreichend. Die Verteilungsstrategie wird durch die Zeilen 20\,f. eingestellt. Hier wird die Strategie \enquote{rolling} verwendet, d.\,.h die einzelnen \enquote{pods} einer/mehrerer \enquote{worker node(s)} werden während dem laufenden Betrieb unbemerkt gegen die neue Version getauscht -- die Endanwenderin bekommt davon nichts mit. Im Gegensatz zu der Variante \enquote{DeploymentConfig} gibt es die \acl{K8s}-Version \enquote{Deployment}, die kompatibel mit \textsc{OpenShift} ist. Sie werden als Nachkomme der \textsc{OpenShift}-Variante (\enquote{DeploymentConfig})\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019} bezeichnet. Die \enquote{Deployment}-Ausprägung beschreibt, wie die \enquote{DeploymentConfig}, den gewünschten Zustand einer Anwendungskomponente in Form einer \enquote{pod}-Vorlage. Der Quellcode \vref{lst:demoDeployment}\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019} erzeugt bei der Ausführung im \textsc{OpenShift}-Cluster eine Replikation des \enquote{hello-openshift}-\enquote{pod}.

\lstinputlisting[language=yaml, caption={Beispiel einer \enquote{Deployment}-Datei}, label=lst:demoDeployment]{resources/listings/deploymentDemo.yaml}

Dabei spezifizieren die Zeilen 16-17, welches \textsc{Docker}-Abbild als Container geladen wird. Die Zeile 19 gibt den Port 80 für die Kommunikation innerhalb des \enquote{pod} frei.
\par
Beide Konfigurationsdatei-Ausprägungen sind vollständig nutzbar in der Anwendungen \textsc{OpenShift}, um eine Verteilung von Komponenten zu beschreiben und auszuführen. \textsc{Red Hat} empfiehlt die Variante \enquote{Deployment} zu nutzen unter der Einschränkung, dass keine Funktionen beziehungsweise kein Verhalten benötigt wird, welches nur die \enquote{DeploymentConfig}-Variante bietet.\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019} Nachfolgend soll betrachtet werden, welche der möglichen Varianten für die \ac{SVI}, begründet durch die Anforderungen der \enquote{stakeholder}, sinnvoll erscheint. Zuvor werden die beiden Möglichkeiten verglichen und die Unterschiede hervorgehoben: Die Varianten unterschieden sich in einem Punkt sehr stark -- dem Design. Genauer formuliert unterscheiden sie sich in der Eigenschaftsauswahl des CAP-Theorem\footnote{\enquote{The CAP theorem states that any networked shared-data system can have at most two of three desirable properties: consistency (C) equivalent to having a single up-to-date copy of the data; high availability (A) of that data (for updates); and tolerance to network partitions (P).}\autocite[][S.\,1]{brewer_cap_2012} CA macht keinen Sinn, da nicht jeder Client dieselben Daten sehen kann und gleichzeitig immer erreichbar ist.}, so bevorzugt die \enquote{DeploymentConfig}- \enquote{consistency} während die \enquote{Deployment}-Variante \enquote{availability} bevorzugt. Übersetzt bedeutet das, wenn der Verteiler-\enquote{pod} während des \enquote{rollouts} der \enquote{DeploymentConfig} einen Fehler aufweist, wartet der komplette Prozess bis die \enquote{node} mit dem \enquote{pod} wieder aktiv wird oder manuell gelöscht wird. Während dieser Phase stockt der Prozess und es wird kein Fortschritt erreicht. Im Gegensatz dazu wird die Verteilung der \enquote{Deployment}-Variante über einen sogenannten \enquote{controller}-Manager durchgeführt, der als Hochverfügbarkeitslösung implementiert ist, d.\,h. die Verfügbarkeit (\enquote{availability}) steht an erster Stelle. Diese Überlegung muss im Rahmen der Prozessmodellierung als erstes in der \ac{SVI} vollzogen werden, um danach die spezifischen Funktionsunterschiede der beiden Konfigurationsdateien weiter zu beleuchten. 
\par
In einer Arbeitstagung zum \ac{PoC} des \textsc{OpenShift}-Systems haben die Entwicklerinnen einen ersten Entwurf für die Konfigurationsdatei vorgestellt. Hier wurde die Version \enquote{Deployment} verwendet -- begründet war dies durch das Argument, dass keine Funktionen der \enquote{DeploymentConfig}-Version benötigt wurden (Dies ist konform zur Aussage von \textsc{Red Hat}\autocite[vgl.][Application\,$\rightarrow$\,Deployments]{red_hat_inc_okd_2019}). Im Anhang \vref{lst:entwurfCamunda} ist die vollständige Version abgedruckt. Wichtig für den \enquote{stakeholder} Entwicklerin ist, die Beschreibung der Umgebungsvariablen, die die Anwendung braucht, um mit zusätzlichen Webservices zu kommunizieren. Der Quellcode \vref{lst:deploymentCamundaEnv} zeigt diese Stelle nochmals, die einer besonderen Analyse bedarf. Es soll ein Algorithmus zur Generierung der Konfigurationsdateien entwickelt werden. Ziel dieses ist es, mögliche Fehler bei der manuellen Erstellung der Datei zu verhindern und ein vollständig automatisierten Prozess zu entwickeln. Die Generierung mittels Programmlösung ist eine Bedingung der Abteilung \ac{IE2}, die die Verantwortung für die Verteilung der Anwendungen tragen.

\lstinputlisting[language=yaml, firstline=17, lastline=42, firstnumber=17, caption={Ausschnitt aus Quellcode \ref{lst:entwurfCamunda}: Deklaration der Umgebungsvaribalen}, label=lst:deploymentCamundaEnv]{resources/listings/camundaEnv.yaml} 

Die Zeichenketten mit dem Muster \enquote{\textit{\$Bezeichner\_}} stellen Platzhalter dar, die genutzt werden, um die eigentlichen Werte nicht in Klartext abzudrucken. Diese fallen unter das Betriebsgeheimnis. Platzhalter mit der gleichen Zeichenkette haben den identischen Inhalt. Es fällt auf, dass die \ac{URL} der Webservices immer mit dem gleichen Host beginnt und ein Teil des Pfades auch gleich ist. Es gibt zwei Möglichkeiten, wie der Algorithmus zur Generierung der Konfigurationsdateien aussehen könnte: Bei der \enquote{Deployment}-Variante müsste dieser die komplette Datei anhand definierter Regeln generieren. Die zweite Möglichkeit ist die Nutzung eines Vorlagen-Objektes (\enquote{template}), das einmal erstellt, unter gewissen Bedingungen, wiederverwendet werden kann. Dies bedeutet, dass für die Beschreibung der Komponenten-Verteilung die \enquote{DeploymentConfig}-Variante genutzt werden muss, da das \enquote{template}-Objekt nur diese Variante unterstützt. Beides sind Eigenentwicklung von \textsc{Red Hat}. Die Ausprägung \enquote{Deployment} ist ein natives \ac{K8s}-Objekt und deswegen nicht mit dem \enquote{template}-Objekt kompatibel. Es besteht die Möglichkeit diese Objekt mit Parametern zu beschreiben, die in einer Datei \lstinline|<Anwendung>.env| gespeichert und mittels der \ac{CLI} eingelesen werden. Diese ersetzt dann die Parameter mit Werten aus der Datei. Die Entscheidung eine \ac{K-V}-Datei, für die Umgebungsvariablen zu nutzen, hat den Vorteil, dass diese extern in einer verteilten Versionsverwaltungsanwendung (beispielsweise \textsc{Git} oder \textsc{Serena Dimensions}) gespeichert werden kann. Nachfolgend ist der Aufbau einer \ac{K-V}-Datei als Quellcode \vref{lst:envCamunda} für die Umgebungsvariablen des Beispiels \vref{lst:entwurfCamunda} angedeutet. Das Trennzeichen zwischen Schlüssel und Wert ist das Gleichheitszeichen (\enquote{=}). Dieser Aufbau ist verpflichtend, wenn die \ac{CLI} von \textsc{OpenShift} genutzt wird.

\lstinputlisting[language=bash, firstline=7, caption={Umgebungsvariablen als \ac{K-V}-Datei}, label={lst:envCamunda}]{resources/listings/CamundaEnv.env.txt}

Eine Anforderung der Abteilung \ac{IE2} ist es, die Konfigurationsdatei über eine Generierung zu erstellen, um mögliche Syntaxfehler ausschließen zu können. Des Weiteren soll so eine Standardisierung der Konfigurationsdatei unternehmensweit erzielt werden. Das Vorgehen dazu soll folgende Stufen enthalten: 


\begin{enumerate}
	\item Eine einheitliche Übergabedatei soll von den Entwicklungsteams in einer Versionsverwaltung abgelegt werden. Die Datei ist nach Vorgaben der Abteilung \ac{IE2} aufgebaut.
	\item Danach soll aus dieser Datei die Konfigurationsdatei erzeugt werden.
	\item Diese wird durch \textsc{OpenShift} validiert, bevor sie ins Cluster geladen wird.
	\item Das Ergebnis ist die vollständige Konfigurationsdatei, die die Komponenten beschreibt, die verteilt werden sollen.
\end{enumerate}

Für die Generierung ist es wichtig ein Grundgerüst der Konfigurationsdatei zu haben. Dieses ist im Anhang \vref{lst:grundConfig} mit beispielhaften Werten zu sehen. Zweck des Grundaufbau ist es, bei der Generierung die fehlenden Informationen möglichst leicht zu integrieren. Dabei hilft es, wenn eine Grundstruktur des Ergebnisses vorhanden ist. Der Aufbau der zulässigen Wortfolgen in einer Zeile der Übergabedatei ist nachfolgend in der Quellcode-Darstellung \vref{lst:bnfDatei} als \ac{BNF}\footnote{\enquote{Using BNF it is possible to specify which sequences of symbols constitute a syntactically valid program in a given language. (The question of semantics--i.e, what such valid strings of symbols mean--must be specified separately.)}\autocite[][]{mccracken_backus-naur_2003}} beschrieben.

\begin{lstlisting}[language=html, caption={\ac{BNF} der Übergabedatei}, label=lst:bnfDatei, mathescape=true]
	$\langle$Zeile$\rangle$ ::= $\langle$Schluessel$\rangle$ $\langle$Zuweisung$\rangle$  $\langle$Wert$\rangle$ $\langle$EOL$\rangle$ | $\langle$Gruppe$\rangle$ $\langle$EOL$\rangle$ | $\lambda$ $\langle$EOL$\rangle$
	$\langle$Schluessel$\rangle$ ::= $\langle$Grossbuchstaben$\rangle$ | $\langle$Grossbuchstaben$\rangle$ $\langle$Schluessel$\rangle$
	$\langle$Zuweisung$\rangle$ ::= "="
	$\langle$Wert$\rangle$ ::= $\langle$Zeichenkette$\rangle$
	$\langle$Gruppe$\rangle$ ::= "$[$" $\langle$Zeichenfolge$\rangle$ "$]$"
	$\langle$Zeichenfolge$\rangle$ ::= $\langle$Grossbuchstaben$\rangle$ | $\langle$Grossbuchstaben$\rangle$ $\langle$Zeichenfolge$\rangle$
	$\langle$Zeichenkette$\rangle$ ::= $\lambda$ | $\langle$Zeichen$\rangle$ | $\langle$Zeichen$\rangle$ $\langle$Zeichenkette$\rangle$
	$\langle$Grossbuchstaben$\rangle$ ::= "A" | "B" | "C" | "D" | "E" | "F" | "G" | "H" | "I" | "J" | "K" | "L" | "M" | "N" | "O" | "P" | "Q" | "R" | "S" | "T" | "U" | "V" | "W" | "X" | "Y" | "Z" | 
	$\langle$Zeichen$\rangle$ ::= "A" | "B" | "C" | "D" | "E" | "F" | "G" | "H" | "I" | "J" | "K" | "L" | "M" | "N" | "O" | "P" | "Q" | "R" | "S" | "T" | "U" | "V" | "W" | "X" | "Y" | "Z" | "_" | "/" | "-" | ":" | "." | "a" | "b" | "c" | "d" | "e" | "f" | "g" | "h" | "i" | "j" | "k" | "l" | "m" | "n" | "o" | "p" | "q" | "r" | "s" | "t" | "u" | "v" | "w" | "x" | "y" | "z"
\end{lstlisting}
Ein Beispiel einer validen Übergabedatei ist im Anhang \ref{lst:bspUbergabe} zur Veranschaulichung des Konzeptes abgebildet. Nachfolgend beschreibt der Algorithmus \ref{algo:configGenerierung} die Logik zur Generierung einer Konfigurationsdatei. Dieser ist absichtlich in Pseudocode verfasst, um den Fokus auf die Logik zu setzen und nicht auf Besonderheiten einer Programmiersprache. Die Idee dieses ist es, die Übergabedatei einzulesen, auszuwerten und auf Basis dieser eine valide Konfigurationsdatei zu erstellen.

\begin{algorithm}[h!]
	\caption{Generierung der Konfigurationsdatei aus einer \ac{K-V}-Datei}\label{algo:configGenerierung}
	
	\begin{algorithmic}
		
		\Procedure{generateDeploymentConfig}{pathToKVFile}
			\State path $\gets$ pathToKVFile
			\State map$[\quad]$$[\quad]$ \Comment{Map with a key and a value, e.g. a array of lines as value}
			\State lines$[\quad]$ $\gets$ \Call{ReadFileByLines}{path}
			\State currentKey = null
			\State yamlTemplate $\gets$ \Call{ReadFile}{pathToYamlTemplate}
			\State
			\ForAll{lines$[\quad]$ as line}
				\If{line like \Call{regEx}{"$\backslash[\{1\}([A-Z]+)\backslash]\{1\}$"}} \Comment{New group element?}
					\State keyword $\gets$ \Call{trim}{line, "$[$", "$]$"}
					\State currentKey $\gets$ keyword
					\State map.\Call{addKey}{currentKey}
				\Else \Comment line contains a k-v-pair
					\State map$[currentKey]$.\Call{add}{line}
				\EndIf
			\EndFor \Comment{All lines of file are stored in k-v-pairs in var map now}
			\State
			
			\State allKeys$[\quad] \gets$ map.\Call{getAllKeys}{}
			\For{i $\gets$ 0, i $\leq$ \Call{length}{allKeys$[\quad]$}, i $++$}
				\ForAll{lines of map$[allKeys[i]]$ as line}
					\State \Call{AddToYaml}{yamlFile, lineToBeAdded, key}
				\EndFor
			\EndFor
		\EndProcedure
	\end{algorithmic}

\end{algorithm}

Ziel des Algorithmus \vref{algo:configGenerierung} ist es, aus einer definierten Übergabedatei (siehe dazu Quellcode \vref{lst:bnfDatei}) die Konfigurationsdateivorlage (\enquote{yamlTemplate}) mit den Übergabedaten anzureichern. Dabei werden zuerst mit einer Schleife alle Zeilen der Übergabedatei eingelesen und nach zwei Kriterien klassifiziert. Kriterium eins beziehungsweise Fall eins bedeutet, dass die Zeile ein neues Gruppenelement (später in der \textsc{Yaml}-Datei das Element der aktuellen Ebene minus eins) enthält. Damit ist ein Schlüsselelement gefunden. Diesem werden nun im alternativen Fall alle folgende Zeilen zu geordnet bis wieder ein Gruppenelement gefunden ist. Nach Beendigung der ersten Schleife sind alle Zeilen in einem \enquote{map}-Objekt als \ac{K-V}-Paare gespeichert. Diese werden an der entsprechenden Stelle der Konfigurationsdatei hinzugefügt. Nach Beendigung dieses Programms ist die Konfigurationsdatei mit den entsprechenden Werten der Übergabedatei beschrieben. 
%Eine mögliche Implementierung des Algorithmus \vref{algo:configGenerierung} ist im Anhang \vref{lst:bspUmsetzungAlgoGen} als \textsc{Python}-Skript abgebildet. \textbf{<Kurzes Statement zum Python-Skript>} 
Ein mögliche Implementierung könnte sich auch die Struktur der \textsc{Yaml}-Datei zu nutze machen: Es gibt für verschiedene Programmiersprachen Module, die eine Objektstruktur in die entsprechende \textsc{Yaml}-Syntax überführen. Mit solch einem Modul wäre die zweite Schleife des Algorithmus \ref{algo:configGenerierung} nicht notwendig. So würde die Objektstruktur eingelesen werden, danach mit mittels Objektmanipulation (wie löschen, hinzufügen beziehungsweise editieren der Attribute) die entsprechenden Stellen angepasst und am Ende des Programms wieder in eine \textsc{Yaml}-Datei überführt. Die aktuelle Version des Algorithmus \ref{algo:configGenerierung} ist bezüglich seiner Laufzeit $T_{P}(x)$\footnote{$T$ entspricht der Laufzeit des Programmes $P$ auf $x$ Eingaben} und der Komplexität $\mathcal{O}$ nicht optimiert. Wenn die oben beschriebene Bibliothek\footnote{hier eine Sammlung von fertigen Programmen zur Verwendung} die \textsc{Yaml}-Datei in eine Struktur übersetzt auf die direkt zugegriffen werden kann, d.\,h. die Komplexität des Zugriffes entspricht $\mathcal{O}(1)$, verbessert sich die Laufzeit $T$ des Algorithmus \vref{algo:configGenerierung} erheblich. Es ist die Verwendungen solch einer Bibliothek zu empfehlen, da die Komplexität des Algorithmus und die Laufzeit verbessert wird. Des Weiteren reduziert sich der Entwicklungsaufwand des Programms, da die Umsetzung der \textsc{Yaml}-Datei ohne zusätzliche Entwicklung einer Funktion auskommt.

\subsection{Prozessmodellierung anhand der Anwendung \textsc{Camunda}}
Die Überschrift dieses Kapitels bezieht sich auf den Verteilungsprozess der Container-Anwendung \textsc{Camunda} und nicht auf die Geschäftsprozessmodellierung, die \textsc{Camunda} anbietet. Dabei ist in dem Container, der verteilt werden soll, der Prozess mit Quellcode abgebildet. Die Formulierung \enquote{Anwendung \textsc{Camunda}} inkludiert sowohl die Anwendung als solche (das \enquote{Base Image} im Wortlaut von \textsc{Docker}) als auch den zusätzliche Quellcode, den die Entwicklungsabteilung erstellt hat. Nachfolgend wird aus platztechnischen Gründen von der \textit{Anwendung \textsc{Camunda}} gesprochen. Die Formulierung \enquote{Prozessmodellierung} bezieht sich auf den oben genannten Verteilungsprozess.
\par
\textsc{Camunda} ist ein freies\footnote{\enquote{open source}, teilweise} \enquote{Workflow}-Management-System, mit dem Geschäftsprozess unter der Verwendung des Standards BPMN 2.0\autocite{object_management_group_omg_business_2011} modelliert und ausgeführt werden können.\autocite[vgl.][]{camunda_services_gmbh_workflow_2020} Es ist in Java geschrieben und als Container-Anwendung in \textsc{Docker} verfügbar. Die \ac{SVI} nutzt zusammen mit ihrem Kunden, der \ac{SV}, die Container-Variante. Die Entwicklungsabteilung beschreibt das Vorgehen zur Entwicklung so: Der Fachbereich des Kunden \ac{SV} entwickelt per \enquote{Drag\&Drop} ein Prozessablaufmodell, dass danach durch die Entwicklungsteams mit Logik (Programmcode in Java) versorgt wird. Für die Prozessmodellierung ist der Aufbau beziehungsweise Inhalt des Containers irrelevant. 
\par
Der Prozess muss zwingend mit der zentralen \enquote{Deployment}-Anwendung \textsc{Ara} erstellt und betrieben werden (vgl. dazu Anforderung $A_{8}$ der Abteilung \ac{IE2}). Die wesentlichen Bestandteile sind die Übergabedatei als \enquote{Input}, die Konfigurationsvorlage als \enquote{Input} und die angereicherte Konfigurationsdatei als \enquote{Output}. Die Übergabedatei wurde per \ac{BNF} in der Quellcodeabbildung \vref{lst:bnfDatei} standardisiert. Diese Grammatik wird der Entwicklungsabteilung zur Verfügung gestellt, um der Entwicklerin den genauen Aufbau der Übergabedatei zu erklären. Dieses Verfahren verhindert Unklarheiten bezüglich der Syntax. Außerdem könnte eine interessierte Entwicklerin ein Programm entwickeln, das auf Grundlage dieser Grammatik die Übergabedatei auf Syntaxfehler überprüft, bevor sie der \enquote{Deployment}-Abteilung \ac{IE2} zur Verfügung gestellt wird. Diese Datei wird in einer Versionsverwaltung (hier \textsc{Serena Dimensions}) übergeben. Nach erfolgreichem Herunterladen der Datei auf einen Arbeitsserver (hier \enquote{DIM.S-V}) beginnt die Verarbeitung dieser Datei. Für diese wird initial der Algorithmus \vref{algo:configGenerierung} verwendet. Zuvor wurde die Konfigurationsdateivorlage aus der Versionsverwaltung auf den Arbeitsserver geladen. Der Algorithmus \vref{algo:configGenerierung} wurde in einer veränderten Form durch die Programmiersprache \textsc{Python} implementiert. Dieser wurde verändert, da \textsc{Python} mit dem Modul \textsc{PyYaml} eine verbesserte Unterstützung bei der Bearbeitung von \textsc{Yaml}-Dateien anbietet. Dabei übersetzt das Modul die \textsc{Yaml}-Datei in ein Objekt, das mit allen möglichen, unterstützen Operation bearbeitet werden kann. Danach wird das Objekt in eine \textsc{Yaml}-Datei umgewandelt. Da die Konfigurationsdatei in diesem Format beschrieben ist, bietet sich diese Vorgehensweise an. Nach erfolgreicher Anreicherung der Konfigurationsdatei muss diese an \textsc{OpenShift} übergeben werden. Dafür ist der Übergabeserver (hier \enquote{OSHIFT.S-V}) zuständig. Dieser Server führt vor Abschluss des Prozesses mehrere Schritt durch: eine Validierung der Konfigurationsdatei, hochladen der Datei auf das \textsc{OpenShift}-Cluster (hier Cluster) ins entsprechende Projekt, die Breitstellung für alle berechtigten Benutzerinnen des Projektes und die aktivieren der Konfiguration, dass dem tatsächlichen Verteilung der Anwendung entspricht. Danach ist diese sichtbar für die Kunden. Um diesen Prozess visuell zu verdeutlichen, wird dieser mit einem adaptierten \ac{UML}-Sequenzdiagramm in Abbildung \vref{abb:prozessDeploymentCamunda} dargestellt. Dieses Vorgehen ist in Kapitel \vref{kap:methodology} begründet.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.39]{img/prozessDeploymentCamunda.pdf}
	\caption{(adaptiertes) Sequenzdiagramm zur Verteilung der Anwendung \textsc{Camunda}}
	{\footnotesize Quelle: eigene Darstellung \par \textit{unternehmensintern}}
	\label{abb:prozessDeploymentCamunda}
\end{figure}
Die Anforderungen $A_{1}, ..., A_{10}$ wurden auf unterschiedliche Weise in diesem Prozess umgesetzt. $A_{1}$ und $A_{2}$ beziehen sich auf die Konfigurationsdatei und die Übergabedatei. Die Anforderungen wurden durch die Standardisierung der Übergabedatei, die Generierung der Konfigurationsdatei und die Validierung dieser umgesetzt. Die Möglichkeit der Definition von Umgebungsvariablen ist in der Übergabedatei gegeben. Über die Konfigurationsdatei werden die Komponenten verteilt. $A_{3}$ beschreibt die Anforderung, dass konsistente Komponenten verteilt werden. Die Validierung dieser erfolgt durch das \textsc{OpenShift}-Cluster und ist somit gewährleistet. Des Weiteren unterstützt der, in Abbildung \vref{abb:prozessDeploymentCamunda}, dargestellte Prozess die Anforderung $A_{4}$, indem eine Konfigurationsdatei als \enquote{Deployment}-Artefakt verteilt wird. Damit ist der Prozess entkoppelt von dem Inhalt des Containers. Anforderung $A_{5}$ bis $A_{7}$ wird durch die direkte Kommunikation (über die \ac{API}) der Verteilungsanwendung \textsc{Ara} erfüllt. \textsc{Ara} kommuniziert ausschließlich über die \textsc{OpenShift}-\ac{API}. Da diese Verteilungsanwendung automatisch und revisions-konform ist, sind alle verbleibenden Anforderungen erfüllt. Die Funktionalitäten der Methoden, die in Abbildung \vref{abb:prozessDeploymentCamunda} verwendet wurden, werden in der Tabelle \vref{tab:methodenFunktion} kurz beschrieben. Dies dient der Übersichtlichkeit und dem Verständnis. 

\begin{table*}[h!]
	\centering
	\ra{1.3} %more space beetween rules
	
	\begin{tabular}{@{}p{5.5cm}p{8.0cm}@{}}\toprule[1.5pt]
		
		\textbf{Methode} & \textbf{Beschreibung} \\ \midrule
		% below rules with content

		
		push(Ü-Datei) & Veröffentlicht die Übergabedatei in der Versionsverwaltung. \\
		holeDatei(Datei) & Lädt die angegebene Datei von der Versionsverwaltung auf einen Server, der die Methode aufgerufen hat. \\
		starteVerteilung(Konfig-Vorlage, Ü-Datei) & Damit wird die Erstellung der angereicherten Konfigurationsdatei gestartet. \\
		sende(Konfig-Datei, Server) & Diese Methode versendet die Konfigurationsdatei an den entsprechend Server. \\
		validieren(Konfig-Datei) & Überprüft die Konfigurationsdatei auf Syntax-Fehler. \\
		hochladen(Konfig-Datei) & Lädt die Datei in \textsc{OpenShift}-Cluster hoch.\\
		stelleBereit(für wen?, Datei) & Diese Methode schaltet die angegebene Datei für alle berechtigten Benutzerinnen auf dem Cluster frei.\\
		setzeSichtbarkeit(Sichtbarkeit) & Veröffentlicht die Komponenten, die durch die Konfigurationsdatei beschrieben wurden. Damit ist der Verteilungsvorgang abgeschlossen.\\
		abbruch(Fehlermeldung) & Bricht den Verteilungsprozess ab und gibt eine Fehlermeldung zurück.\\
		
		\bottomrule[1.5pt]
	\end{tabular}
	
	\caption{Überblick über die verwendeten Methoden in Abbildung \vref{abb:prozessDeploymentCamunda}}
	\label{tab:methodenFunktion}
	
\end{table*}
 
\section{Ergebnis der Forschungsfrage eins}
Die Ergebnisse der Forschungsfrage eins -- Wie können Container-Anwendungen den Prozess des automatisierten \enquote{Deployments} unterstützen? -- werden nachfolgend kurz zusammengefasst. Eine kritische Betrachtung des gesamten Ergebnisses der Bachelorarbeit ist im Epilog (siehe Kapitel \vref{kritischeBetrachtung}) zu finden.

\paragraph{Prozess wird generisch(er)} Durch die Verwendung dieses Prozess können in Zukunft viele Anwendungen mit nur einem Prozess verteilt werden. Dies ist bedingt durch die Entkopplung der Verteilungslogik und dem eigentlichen Prozess. Da \textsc{OpenShift} nach dem Erhalt der Konfigurationsdatei die wirkliche Verteilung der Komponenten übernimmt, hat sich das komplette Verständnis eines \enquote{Deployments} innerhalb der \ac{SVI} verändert beziehungsweise wird sich verändern. Der neuartige Prozess verteilt nur noch die Konfiguration(-sdatei) und nicht, wie bei den vorherigen Prozessen, den Programmcode oder das Kompilat des Codes. Damit kann der Prozess eine Verteilungsobjekt-unabhängige Logik verwenden. Dieser profitiert von den oben genannten Vorteilen der Container-Anwendungen (vgl. dazu \vref{kap:container}). Des Weiteren profitiert die Endkundin von der ständigen Verfügbarkeit der \enquote{Cloud}, da eine Verteilung einer neuen Version während der Betriebszeiten gemacht werden kann -- dadurch wird eine schnellere \ac{TTM} erreicht. Der, in Abbildung \vref{abb:prozessDeploymentCamunda} abgebildete, Prozess stellt einen ersten Versuch einer automatisierten Verteilung (von Container-Anwendungen) dar. In weiteren Evaluierungen muss der neue Prozess seine Vorteile unter Beweis stellen. Bis dieser von den Verantwortlichen freigegeben wird und produktiv geht, sind noch einige Schritte notwendig, wie z.\,B. die Qualitätssicherung und die Prüfung auf Revisions-Tauglichkeit.

\paragraph{Aufwand ist langfristig geringer} Dieser Teil des Ergebnisses folgt aus der Aussage, dass der Prozess generischer wird: Der anfängliche Aufwand der Entwicklung eines Container-\enquote{Deployment}-Prozesses ist im Unternehmen \ac{SVI} höher, da noch kein Wissen über die Container-/\enquote{Cloud}-Technologie vorhanden war. Des Weiteren gab es kein etabliertes Vorgehen, wie Container-Anwendungen im Bereich der Verteilung behandelt werden. So musste eine Übergabe- und Konfigurationsdatei entwickelt werden, die Infrastruktur (nicht Teil dieser Arbeit) für \textsc{OpenShift} und Container-/\enquote{Cloud}-Produkte geschaffen werden. Außerdem wurden Regeln entwickelt (nicht Teil dieser Arbeit), wie die Zusammenarbeit zwischen den einzelnen, beteiligten Abteilungen funktioniert. Ist der Verteilungsprozess entwickelt und läuft stabil, benötigt dieser keinen weiteren Entwicklungsaufwand. Solange die Anforderungen der Plattform \enquote{OpenShift} nicht verändern, benötigt der Prozess fachlich keine Weiterentwicklung. Somit pendelt sich der Aufwand auf einem konstant niedrigem Niveau ein. Die verbleibenden, aufwand-verursachenden Aufgaben beschränken sich auf die Betreuung im Fehlerfall (Konfigurationsdatei ist fachlich nicht korrekt) und auf die Überwachung der Verteilung neuer Anwendungen. Im Gegensatz dazu stehen die aktuellen Prozesse, die für die Bestandssysteme der \ac{SV} implementiert sind. Hier müssen ständig Anpassungen am Verteilungsprozess gemacht werden, da Kompilate und Quellcode verteilt wird und der \enquote{Deployment}-Prozess auch Kompilierungen vornimmt.
 
\paragraph{Verbesserte Kontrolle des Erfolges} Dies ist bedingt durch die Verteilung einer einzigen Konfigurationsdatei während eines \enquote{Deployments}. Es müssen nicht mehr tausende Artefakte eines Programms verteilt werden. Dadurch ist die Kontrolle des Erfolges beziehungsweise Misserfolges im Vergleich zum jetzigen Prozess einfacher. Im Fehlerfall muss eine Datei, die Konfigurationsdatei, überprüft werden. Die Generierung dieser Datei beschränkt sich auf einen Generierungsalgorithmus, der aus einer Übergabedatei die Konfigurierung ableitet. Wenn dieser getestet ist und fehlerfrei läuft, ist die Fehlerquelle bei einer falschen Verteilung von Komponenten initial beschränkt auf die Übergabedatei. Diese kann einfach kontrolliert und verbessert werden. Es sind immer noch Fehler möglich, jedoch ist die Anzahl der möglichen Fehlerquellen gesunken.

\paragraph{Kritik am Generierungsalgorithmus \ref{algo:configGenerierung}} Dieser Algorithmus \vref{algo:configGenerierung} ist, wie schon erwähnt, bezüglich seiner Laufzeit $T(x)$ und Komplexität $\mathcal{O}$ nicht optimiert. Somit Bedarf dieser noch weiteren Verbesserungen, um die Leistung zu steigern. Problematisch sind die ineinander kombinierten Schleifen, da sie die Laufzeit im schlechtesten Fall polynominell, d.\,h. pro Schleife erhöht sich der (positive) Exponent von $n^{c}$  um eins und damit die Komplexitätsklasse $\mathcal{O}(n^{c}),\,c \ge 1$. Wie oben beschrieben kann über die Vermeidung von ineinander kombinierten Schleifen die Komplexität klein gehalten werden. Eine erste Möglichkeit ist es, das Modul \textsc{PyYaml} zu nutzen, dass durch die Übersetzung der Konfigurationsdatei in ein \ac{K-V}-Objekt Zugriffe der Komplexität $\mathcal{O}(1)$ zulässt. Die Komplexität $\mathcal{O}(1)$ bedeutet übersetzt in diesem Kontext ein direkter Zugriff auf ein Element.

\paragraph{Ausblick: Weitere Evaluierung notwendig} Um die Qualität des Prozesses weiter zu verbessern, sind weitere Schritte notwendig. So müssen die Regeln zur Übergabe der Dateien, zum Aufbau der Konfigurationsdatei und zur Zusammenarbeit erstellt beziehungsweise verbessert werden. Auch müssen Management-Entscheidungen zur Standardisierung dieses Prozess angestoßen und verfolgt werden. Eine weitere Empfehlung ist, den langfristigen Nutzen dieses Prozess zu analysieren, um Verbesserungspotentiale zu finden. Die Forschungsfrage eins versteht sich als ersten Versuch ein lauffähiges Container-\enquote{Deployment} in der \ac{SVI} zu entwickeln -- es sind weitere Schritte bis zum Produktivgang des Prozesses nötig.